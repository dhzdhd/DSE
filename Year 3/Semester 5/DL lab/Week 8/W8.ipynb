{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291dfda1-b6a2-460a-b41b-593b8bb1d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:50:24.173973: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-25 09:50:24.197916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 09:50:24.551320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Embedding, Dropout, Input, Concatenate, TimeDistributed\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d70dc8e-be63-4506-ae36-415a10d29d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hin.txt','r') as f:\n",
    "  data = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed09f88",
   "metadata": {},
   "source": [
    "## Q1) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59aecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncleaned_data_list = data.split('\\n')\n",
    "uncleaned_data_list.pop()\n",
    "len(uncleaned_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ca1019-21fc-41df-8bff-224f4a0c04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_word = []\n",
    "hindi_word = []\n",
    "cleaned_data_list = []\n",
    "\n",
    "for word in uncleaned_data_list:\n",
    "  split = word.split('\\t')\n",
    "  english_word.append(split[0])\n",
    "  hindi_word.append(split[1])\n",
    "\n",
    "language_data = pd.DataFrame(columns=['English','Hindi'])\n",
    "language_data['English'] = english_word\n",
    "language_data['Hindi'] = hindi_word\n",
    "language_data.to_csv('language_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e4d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English  Hindi\n",
       "0    Wow!   वाह!\n",
       "1   Duck!  झुको!\n",
       "2   Duck!  बतख़!\n",
       "3   Help!  बचाओ!\n",
       "4   Jump.  उछलो."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d65f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2979, 2979)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text = language_data['English'].values\n",
    "hindi_text = language_data['Hindi'].values\n",
    "len(english_text), len(hindi_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b6cb9d-f099-4d46-87b3-edeb4edc30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text_ = [x.lower() for x in english_text]\n",
    "hindi_text_ = [x.lower() for x in hindi_text]\n",
    "\n",
    "english_text_ = [re.sub(\"'\",'',x) for x in english_text_]\n",
    "hindi_text_ = [re.sub(\"'\",'',x) for x in hindi_text_]\n",
    "\n",
    "def remove_punc(text_list):\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  removed_punc_text = []\n",
    "  for sent in text_list:\n",
    "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
    "    removed_punc_text.append(' '.join(sentance))\n",
    "  return removed_punc_text\n",
    "\n",
    "english_text_ = remove_punc(english_text_)\n",
    "hindi_text_ = remove_punc(hindi_text_)\n",
    "\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "removed_digits_text = []\n",
    "for sent in english_text_:\n",
    "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
    "  removed_digits_text.append(' '.join(sentance))\n",
    "\n",
    "english_text_ = removed_digits_text\n",
    "hindi_text_ = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in hindi_text_]\n",
    "hindi_text_ = [re.sub(\"[\\u200d]\",\"\",x) for x in hindi_text_]\n",
    "\n",
    "english_text_ = [x.strip() for x in english_text_]\n",
    "hindi_text_ = [x.strip() for x in hindi_text_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8e68d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start वाह end', 'wow')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_text_ = [\"start \" + x + \" end\" for x in hindi_text_]\n",
    "hindi_text_[0], english_text_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8588f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = english_text_\n",
    "Y = hindi_text_\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37cca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_length(data):\n",
    "  max_length_ = max([len(x.split(' ')) for x in data])\n",
    "  return max_length_\n",
    "\n",
    "max_length_english = max_length(X_train)\n",
    "max_length_hindi = max_length(y_train)\n",
    "max_length_english_test = max_length(X_test)\n",
    "max_length_hindi_test = max_length(y_test)\n",
    "max_length_hindi, max_length_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a512bc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270, 2890)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishTokenizer = Tokenizer()\n",
    "englishTokenizer.fit_on_texts(X_train)\n",
    "Eword2index = englishTokenizer.word_index\n",
    "vocab_size_source = len(Eword2index) + 1\n",
    "\n",
    "X_train = englishTokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
    "X_test = englishTokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen = max_length_english, padding='post')\n",
    "\n",
    "hindiTokenizer = Tokenizer()\n",
    "hindiTokenizer.fit_on_texts(y_train)\n",
    "Hword2index = hindiTokenizer.word_index\n",
    "vocab_size_target = len(Hword2index) + 1\n",
    "\n",
    "y_train = hindiTokenizer.texts_to_sequences(y_train)\n",
    "y_train = pad_sequences(y_train, maxlen=max_length_hindi, padding='post')\n",
    "y_test = hindiTokenizer.texts_to_sequences(y_test)\n",
    "y_test = pad_sequences(y_test, maxlen = max_length_hindi, padding='post')\n",
    "\n",
    "vocab_size_source, vocab_size_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99cb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf2d67",
   "metadata": {},
   "source": [
    "## Q2) Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7236bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "logger = tf.get_logger()\n",
    "\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(\n",
    "            name=\"W_a\",\n",
    "            shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.U_a = self.add_weight(\n",
    "            name=\"U_a\",\n",
    "            shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.V_a = self.add_weight(\n",
    "            name=\"V_a\",\n",
    "            shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        super(AttentionLayer, self).build(\n",
    "            input_shape\n",
    "        )  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "\n",
    "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
    "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\"Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            logger.debug(\"Running energy computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(\n",
    "                    f\"States must be an iterable. Got {states} of type {type(states)}\"\n",
    "                )\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_full_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(\n",
    "                K.dot(inputs, self.U_a), 1\n",
    "            )  # <= batch_size, 1, latent_dim\n",
    "\n",
    "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "\n",
    "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\"Step function for computing ci using ei\"\"\"\n",
    "\n",
    "            logger.debug(\"Running attention vector computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(\n",
    "                    f\"States must be an iterable. Got {states} of type {type(states)}\"\n",
    "                )\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "\n",
    "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
    "\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        # we don't maintain states between steps when computing attention\n",
    "        # attention is stateless, so we're passing a fake state for RNN step function\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(\n",
    "            encoder_out_seq, axis=2\n",
    "        )  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"Outputs produced by the layer\"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1])),\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f771125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:50:25.266962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.281321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.281428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.282628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.282717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.282780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.615654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.615781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.615842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-25 09:50:25.615894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9948 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-10-25 09:50:25.836029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:25.836576: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:25.837074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:25.957950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:25.958668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:25.959143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:26.075896: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:26.076596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:26.077238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 22, 500)      1135000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 22, 500),    2002000     ['embedding[0][0]']              \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 22, 500),    2002000     ['lstm[0][0]']                   \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 500)    1445000     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 22, 500),    2002000     ['lstm_1[0][0]']                 \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
      "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 500),  500500     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 22))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 1000)   0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 2890)  2892890     ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,981,390\n",
      "Trainable params: 13,981,390\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:50:26.199443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:26.199995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:26.200624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "latent_dim = 500\n",
    "\n",
    "encoder_inputs = Input(shape=(max_length_english,))\n",
    "enc_emb = Embedding(vocab_size_source, latent_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(vocab_size_target, latent_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "attn_layer = AttentionLayer()\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf63012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47415a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:50:26.532891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:26.533932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:26.534609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:26.624347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:26.625018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:26.625615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:26.712876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:26.713582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:26.714174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:26.801948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:26.802743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:26.803366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:27.645156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:27.646459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:27.647050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:27.729294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:27.729950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:27.730513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:27.913296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:27.914071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:27.914779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:28.002235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:28.002969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:28.003558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:29.606768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-25 09:50:29.721792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-25 09:50:29.809152: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x23110360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-25 09:50:29.809167: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-10-25 09:50:29.811743: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-25 09:50:29.874146: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 6.1513 - accuracy: 0.5662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:50:31.514140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:31.515563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:31.516978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:31.606976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:31.607621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:31.608181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:31.692062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:31.692730: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:31.693296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:50:31.778943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:50:31.779839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:50:31.780455: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 6s 352ms/step - loss: 6.1513 - accuracy: 0.5662 - val_loss: 2.3802 - val_accuracy: 0.7108\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 2.2166 - accuracy: 0.7006 - val_loss: 1.9322 - val_accuracy: 0.7108\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 2.0242 - accuracy: 0.7042 - val_loss: 1.9163 - val_accuracy: 0.7144\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 2.0015 - accuracy: 0.7059 - val_loss: 1.8720 - val_accuracy: 0.7158\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 1s 215ms/step - loss: 1.9711 - accuracy: 0.7039 - val_loss: 1.8396 - val_accuracy: 0.7164\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 1.9377 - accuracy: 0.7052 - val_loss: 1.8268 - val_accuracy: 0.7158\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 1s 221ms/step - loss: 1.9273 - accuracy: 0.7062 - val_loss: 1.8332 - val_accuracy: 0.7150\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.9328 - accuracy: 0.7045 - val_loss: 1.7771 - val_accuracy: 0.7216\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 1s 216ms/step - loss: 1.8799 - accuracy: 0.7079 - val_loss: 1.7833 - val_accuracy: 0.7162\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 1s 215ms/step - loss: 1.9347 - accuracy: 0.7026 - val_loss: 1.7955 - val_accuracy: 0.7168\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 1s 215ms/step - loss: 1.8801 - accuracy: 0.7105 - val_loss: 1.7634 - val_accuracy: 0.7194\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 1s 214ms/step - loss: 1.8772 - accuracy: 0.7092 - val_loss: 1.7606 - val_accuracy: 0.7162\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 1s 221ms/step - loss: 1.8536 - accuracy: 0.7105 - val_loss: 1.7638 - val_accuracy: 0.7188\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 1.8535 - accuracy: 0.7093 - val_loss: 1.7296 - val_accuracy: 0.7241\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 1s 218ms/step - loss: 1.8249 - accuracy: 0.7160 - val_loss: 1.7028 - val_accuracy: 0.7244\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.8125 - accuracy: 0.7179 - val_loss: 1.6975 - val_accuracy: 0.7220\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 1s 216ms/step - loss: 1.7869 - accuracy: 0.7231 - val_loss: 1.6629 - val_accuracy: 0.7255\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.7553 - accuracy: 0.7248 - val_loss: 1.6594 - val_accuracy: 0.7201\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 1s 218ms/step - loss: 1.7490 - accuracy: 0.7242 - val_loss: 1.6302 - val_accuracy: 0.7384\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.7266 - accuracy: 0.7326 - val_loss: 1.6432 - val_accuracy: 0.7303\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.7222 - accuracy: 0.7325 - val_loss: 1.6161 - val_accuracy: 0.7452\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.7114 - accuracy: 0.7346 - val_loss: 1.6067 - val_accuracy: 0.7415\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.6941 - accuracy: 0.7415 - val_loss: 1.5988 - val_accuracy: 0.7539\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 1.7048 - accuracy: 0.7419 - val_loss: 1.5918 - val_accuracy: 0.7536\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 1.6806 - accuracy: 0.7446 - val_loss: 1.5838 - val_accuracy: 0.7561\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 1.6892 - accuracy: 0.7434 - val_loss: 1.5774 - val_accuracy: 0.7515\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 1s 218ms/step - loss: 1.6748 - accuracy: 0.7441 - val_loss: 1.5769 - val_accuracy: 0.7543\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.6722 - accuracy: 0.7442 - val_loss: 1.5770 - val_accuracy: 0.7523\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.6701 - accuracy: 0.7447 - val_loss: 1.5719 - val_accuracy: 0.7543\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 1s 218ms/step - loss: 1.6577 - accuracy: 0.7442 - val_loss: 1.5710 - val_accuracy: 0.7549\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 1.6680 - accuracy: 0.7441 - val_loss: 1.5705 - val_accuracy: 0.7535\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 1s 216ms/step - loss: 1.6534 - accuracy: 0.7449 - val_loss: 1.5717 - val_accuracy: 0.7536\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 1s 216ms/step - loss: 1.6559 - accuracy: 0.7445 - val_loss: 1.5604 - val_accuracy: 0.7544\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 1.6508 - accuracy: 0.7446 - val_loss: 1.5685 - val_accuracy: 0.7544\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 1s 210ms/step - loss: 1.6438 - accuracy: 0.7446 - val_loss: 1.5520 - val_accuracy: 0.7550\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.6327 - accuracy: 0.7454 - val_loss: 1.5683 - val_accuracy: 0.7536\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 1.6535 - accuracy: 0.7446 - val_loss: 1.5532 - val_accuracy: 0.7566\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 1.6293 - accuracy: 0.7452 - val_loss: 1.5516 - val_accuracy: 0.7548\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.6672 - accuracy: 0.7419 - val_loss: 1.5494 - val_accuracy: 0.7561\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 1s 209ms/step - loss: 1.6246 - accuracy: 0.7451 - val_loss: 1.5440 - val_accuracy: 0.7541\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 1s 216ms/step - loss: 1.6204 - accuracy: 0.7454 - val_loss: 1.5477 - val_accuracy: 0.7576\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.6433 - accuracy: 0.7444 - val_loss: 1.5483 - val_accuracy: 0.7549\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 1s 217ms/step - loss: 1.6218 - accuracy: 0.7448 - val_loss: 1.5514 - val_accuracy: 0.7541\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 1s 209ms/step - loss: 1.6226 - accuracy: 0.7450 - val_loss: 1.5461 - val_accuracy: 0.7562\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 1s 209ms/step - loss: 1.6096 - accuracy: 0.7453 - val_loss: 1.5459 - val_accuracy: 0.7557\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 1s 212ms/step - loss: 1.6183 - accuracy: 0.7454 - val_loss: 1.5758 - val_accuracy: 0.7501\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 1s 212ms/step - loss: 1.6154 - accuracy: 0.7453 - val_loss: 1.5412 - val_accuracy: 0.7577\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 1.6015 - accuracy: 0.7460 - val_loss: 1.5488 - val_accuracy: 0.7539\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.6271 - accuracy: 0.7444 - val_loss: 1.5459 - val_accuracy: 0.7536\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 1s 219ms/step - loss: 1.6041 - accuracy: 0.7457 - val_loss: 1.5480 - val_accuracy: 0.7537\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train, y_train[:, :-1]],\n",
    "    y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    validation_data=(\n",
    "        [X_test, y_test[:, :-1]],\n",
    "        y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:, 1:],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df364a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "034a9e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:51:36.533329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:51:36.533939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:51:36.534509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "latent_dim=500\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h, state_c = model.layers[6].output\n",
    "\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(22,latent_dim))\n",
    "\n",
    "decoder_inputs = model.layers[3].output\n",
    "\n",
    "dec_emb_layer = model.layers[5]\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = model.layers[7]\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "attn_layer = model.layers[8]\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "concate = model.layers[9]\n",
    "decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "decoder_dense = model.layers[10]\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b48368",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eindex2word = englishTokenizer.index_word\n",
    "Hindex2word = hindiTokenizer.index_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50320e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    target_seq[0, 0] = Hword2index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        if sampled_token_index == 0:\n",
    "            break\n",
    "        else:\n",
    "            sampled_token = Hindex2word[sampled_token_index]\n",
    "            if sampled_token != 'end':\n",
    "                decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        if sampled_token == 'end' or len(decoded_sentence.split()) >= (26-1):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0385150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString = \"\"\n",
    "    for i in input_seq:\n",
    "        if (i != 0 and i != Hword2index[\"start\"]) and i != Hword2index[\"end\"]:\n",
    "            newString = newString + Hindex2word[i] + \" \"\n",
    "    return newString\n",
    "\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString = \"\"\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + Eindex2word[i] + \" \"\n",
    "    return newString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "794ef085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:51:36.731767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:51:36.732745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:51:36.733313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: i am doing business on a large \n",
      "Original summary: मैं बड़े पर व्यापार कर रहा हूँ। \n",
      "(22,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:51:36.816755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:51:36.817403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:51:36.817959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 09:51:36.900230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:51:36.900846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:51:36.901371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 09:51:37.122842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 09:51:37.123485: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 09:51:37.124129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  वह एक में में\n",
      "\n",
      "\n",
      "Review: where do you live \n",
      "Original summary: तू कहाँ रहती है \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  क्या क्या\n",
      "\n",
      "\n",
      "Review: what is happiness \n",
      "Original summary: क्या होता है \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  क्या क्या\n",
      "\n",
      "\n",
      "Review: it is to have good of english nowadays \n",
      "Original summary: आजकल अंग्रेज़ी अच्छे से बोलना जानना बहुत ज़रूरी है। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicted summary:  तुम एक में\n",
      "\n",
      "\n",
      "Review: stand still and keep \n",
      "Original summary: शांति से खड़े \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Predicted summary:  क्या क्या\n",
      "\n",
      "\n",
      "Review: business is so these days \n",
      "Original summary: कारोबार में आजकल पड़ गई है। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  क्या क्या\n",
      "\n",
      "\n",
      "Review: both of my sisters are married \n",
      "Original summary: मेरी दोनो शादीशुदा हैं। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  तुम एक में\n",
      "\n",
      "\n",
      "Review: they are the problem \n",
      "Original summary: वे इस समस्या के बारे में बातचीत कर रहे हैं। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  क्या क्या\n",
      "\n",
      "\n",
      "Review: you must get rid of such a habit \n",
      "Original summary: तुम्हें इस तरह की आदत तोड़ देनी चाहिए। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicted summary:  वह एक में में\n",
      "\n",
      "\n",
      "Review: this box contains five apples \n",
      "Original summary: इस डब्बे में पाँच सेव हैं। \n",
      "(22,)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Predicted summary:  तुम एक में\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Review:\", seq2text(X_test[i]))\n",
    "    print(\"Original summary:\", seq2summary(y_test[i]))\n",
    "    print(X_test[i].shape)\n",
    "    print(\"Predicted summary:\", decode_sequence(X_test[i].reshape(1, 22)))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de5f37",
   "metadata": {},
   "source": [
    "## Q3) Pretrained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11e65504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce6777fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"t5-small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74f12542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/tasks/translation\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "model_name = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(list(language_data[\"English\"]), text_target=list(language_data[\"Hindi\"]), truncation=True, padding=True, max_length=200)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name, return_tensors=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3434845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d225612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "203e0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0483dfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9b3766f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/aiohttp/client_reqrep.py:70\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcchardet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cchardet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf_train_set \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mprepare_tf_dataset(\n\u001b[1;32m      2\u001b[0m     train_encodings,\n\u001b[1;32m      3\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      5\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1438\u001b[0m, in \u001b[0;36mTFPreTrainedModel.prepare_tf_dataset\u001b[0;34m(self, dataset, batch_size, shuffle, tokenizer, collate_fn, collate_fn_args, drop_remainder, prefetch)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;124;03mWraps a HuggingFace [`~datasets.Dataset`] as a `tf.data.Dataset` with collation and batching. This method is\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;124;03mdesigned to create a \"ready-to-use\" dataset that can be passed directly to Keras methods like `fit()` without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;124;03m    `Dataset`: A `tf.data.Dataset` which is ready to pass to the Keras API.\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1438\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/datasets/__init__.py:43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m pyarrow\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m version\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/datasets/arrow_dataset.py:65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/datasets/arrow_reader.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _split_re, filenames_for_dataset_split\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryTable, MemoryMappedTable, Table, concat_tables\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/datasets/download/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadManager, DownloadMode\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_download_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/datasets/download/streaming_download_manager.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElementTree \u001b[38;5;28;01mas\u001b[39;00m ET\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maiohttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientError\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilesystems\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPRESSION_FILESYSTEMS\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/aiohttp/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hdrs \u001b[38;5;28;01mas\u001b[39;00m hdrs\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     BaseConnector \u001b[38;5;28;01mas\u001b[39;00m BaseConnector,\n\u001b[1;32m      8\u001b[0m     ClientConnectionError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectionError,\n\u001b[1;32m      9\u001b[0m     ClientConnectorCertificateError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorCertificateError,\n\u001b[1;32m     10\u001b[0m     ClientConnectorError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorError,\n\u001b[1;32m     11\u001b[0m     ClientConnectorSSLError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorSSLError,\n\u001b[1;32m     12\u001b[0m     ClientError \u001b[38;5;28;01mas\u001b[39;00m ClientError,\n\u001b[1;32m     13\u001b[0m     ClientHttpProxyError \u001b[38;5;28;01mas\u001b[39;00m ClientHttpProxyError,\n\u001b[1;32m     14\u001b[0m     ClientOSError \u001b[38;5;28;01mas\u001b[39;00m ClientOSError,\n\u001b[1;32m     15\u001b[0m     ClientPayloadError \u001b[38;5;28;01mas\u001b[39;00m ClientPayloadError,\n\u001b[1;32m     16\u001b[0m     ClientProxyConnectionError \u001b[38;5;28;01mas\u001b[39;00m ClientProxyConnectionError,\n\u001b[1;32m     17\u001b[0m     ClientRequest \u001b[38;5;28;01mas\u001b[39;00m ClientRequest,\n\u001b[1;32m     18\u001b[0m     ClientResponse \u001b[38;5;28;01mas\u001b[39;00m ClientResponse,\n\u001b[1;32m     19\u001b[0m     ClientResponseError \u001b[38;5;28;01mas\u001b[39;00m ClientResponseError,\n\u001b[1;32m     20\u001b[0m     ClientSession \u001b[38;5;28;01mas\u001b[39;00m ClientSession,\n\u001b[1;32m     21\u001b[0m     ClientSSLError \u001b[38;5;28;01mas\u001b[39;00m ClientSSLError,\n\u001b[1;32m     22\u001b[0m     ClientTimeout \u001b[38;5;28;01mas\u001b[39;00m ClientTimeout,\n\u001b[1;32m     23\u001b[0m     ClientWebSocketResponse \u001b[38;5;28;01mas\u001b[39;00m ClientWebSocketResponse,\n\u001b[1;32m     24\u001b[0m     ContentTypeError \u001b[38;5;28;01mas\u001b[39;00m ContentTypeError,\n\u001b[1;32m     25\u001b[0m     Fingerprint \u001b[38;5;28;01mas\u001b[39;00m Fingerprint,\n\u001b[1;32m     26\u001b[0m     InvalidURL \u001b[38;5;28;01mas\u001b[39;00m InvalidURL,\n\u001b[1;32m     27\u001b[0m     NamedPipeConnector \u001b[38;5;28;01mas\u001b[39;00m NamedPipeConnector,\n\u001b[1;32m     28\u001b[0m     RequestInfo \u001b[38;5;28;01mas\u001b[39;00m RequestInfo,\n\u001b[1;32m     29\u001b[0m     ServerConnectionError \u001b[38;5;28;01mas\u001b[39;00m ServerConnectionError,\n\u001b[1;32m     30\u001b[0m     ServerDisconnectedError \u001b[38;5;28;01mas\u001b[39;00m ServerDisconnectedError,\n\u001b[1;32m     31\u001b[0m     ServerFingerprintMismatch \u001b[38;5;28;01mas\u001b[39;00m ServerFingerprintMismatch,\n\u001b[1;32m     32\u001b[0m     ServerTimeoutError \u001b[38;5;28;01mas\u001b[39;00m ServerTimeoutError,\n\u001b[1;32m     33\u001b[0m     TCPConnector \u001b[38;5;28;01mas\u001b[39;00m TCPConnector,\n\u001b[1;32m     34\u001b[0m     TooManyRedirects \u001b[38;5;28;01mas\u001b[39;00m TooManyRedirects,\n\u001b[1;32m     35\u001b[0m     UnixConnector \u001b[38;5;28;01mas\u001b[39;00m UnixConnector,\n\u001b[1;32m     36\u001b[0m     WSServerHandshakeError \u001b[38;5;28;01mas\u001b[39;00m WSServerHandshakeError,\n\u001b[1;32m     37\u001b[0m     request \u001b[38;5;28;01mas\u001b[39;00m request,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcookiejar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CookieJar \u001b[38;5;28;01mas\u001b[39;00m CookieJar, DummyCookieJar \u001b[38;5;28;01mas\u001b[39;00m DummyCookieJar\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FormData \u001b[38;5;28;01mas\u001b[39;00m FormData\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/aiohttp/client.py:59\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractCookieJar\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     ClientConnectionError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectionError,\n\u001b[1;32m     40\u001b[0m     ClientConnectorCertificateError \u001b[38;5;28;01mas\u001b[39;00m ClientConnectorCertificateError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     WSServerHandshakeError \u001b[38;5;28;01mas\u001b[39;00m WSServerHandshakeError,\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_reqrep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     ClientRequest \u001b[38;5;28;01mas\u001b[39;00m ClientRequest,\n\u001b[1;32m     61\u001b[0m     ClientResponse \u001b[38;5;28;01mas\u001b[39;00m ClientResponse,\n\u001b[1;32m     62\u001b[0m     Fingerprint \u001b[38;5;28;01mas\u001b[39;00m Fingerprint,\n\u001b[1;32m     63\u001b[0m     RequestInfo \u001b[38;5;28;01mas\u001b[39;00m RequestInfo,\n\u001b[1;32m     64\u001b[0m     _merge_ssl_params,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient_ws\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientWebSocketResponse \u001b[38;5;28;01mas\u001b[39;00m ClientWebSocketResponse\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     68\u001b[0m     BaseConnector \u001b[38;5;28;01mas\u001b[39;00m BaseConnector,\n\u001b[1;32m     69\u001b[0m     NamedPipeConnector \u001b[38;5;28;01mas\u001b[39;00m NamedPipeConnector,\n\u001b[1;32m     70\u001b[0m     TCPConnector \u001b[38;5;28;01mas\u001b[39;00m TCPConnector,\n\u001b[1;32m     71\u001b[0m     UnixConnector \u001b[38;5;28;01mas\u001b[39;00m UnixConnector,\n\u001b[1;32m     72\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/aiohttp/client_reqrep.py:72\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcchardet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[no-redef]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClientRequest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClientResponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequestInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFingerprint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/charset_normalizer/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[0;32m~/anaconda3/envs/dse/lib/python3.11/site-packages/charset_normalizer/api.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m     PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike[str]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    train_encodings,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbcee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ae8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
